{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# EDGAR Ground Truth Combined Extraction (Full Context)\n",
        "\n",
        "**Goal**: Extract all 8 fields from SEC 10-K filings with evidence provenance.\n",
        "\n",
        "**Model**: Llama 3.3 70B Instruct via vLLM on Lambda GPU\n",
        "\n",
        "**Strategy**: Per-field sequential extraction with JSON structured output.\n",
        "\n",
        "**Output**: CSV with `{field}_value`, `{field}_evidence`, `{field}_source_sentence`, `{field}_evidence_verified` for each field."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```bash \n",
        "# SSH into the instance, create a conda env, install everything fresh:\n",
        "conda create -n vllm_env python=3.11 -y\n",
        "conda activate vllm_env\n",
        "pip install vllm datasets pandas tqdm thefuzz python-Levenshtein jupyter\n",
        "# Start JupyterLab yourself\n",
        "jupyter lab --ip=0.0.0.0 --port=8888 --no-browser \n",
        "``` \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Installation (Run once on Lambda) \n",
        "#%env HF_TOKEN=your_token\n",
        "#!pip install torch torchvision torchaudio vllm datasets pandas transformers tqdm thefuzz python-Levenshtein ipykernel notebook accelerate huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2. Imports & Setup\n",
        "import os\n",
        "import re\n",
        "import gc\n",
        "import json\n",
        "import pandas as pd\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from datasets import load_dataset\n",
        "from vllm import LLM, SamplingParams\n",
        "from huggingface_hub import login  \n",
        "\n",
        "pd.set_option('display.max_colwidth', None) \n",
        "login(token=os.environ[\"HF_TOKEN\"]) # or login(token=\"your_token\")\n",
        "print(\"Setup Complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3. Load Model (Llama 3.3 70B Instruct via vLLM)\n",
        "\n",
        "MODEL_NAME = \"meta-llama/Llama-3.3-70B-Instruct\"\n",
        "\n",
        "print(f\"Loading {MODEL_NAME} via vLLM...\")\n",
        "llm = LLM(\n",
        "    model=MODEL_NAME,\n",
        "    tensor_parallel_size=torch.cuda.device_count(),  # Use all available GPUs\n",
        "    max_model_len=65536,  # 64K context to fit ~50-60K docs with room for output\n",
        "    enable_prefix_caching=True,  # Reduces attention dilution\n",
        "    gpu_memory_utilization=0.90,\n",
        "    dtype=\"bfloat16\",\n",
        ")\n",
        "print(f\"Model loaded on {torch.cuda.device_count()} GPU(s).\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4. Configuration\n",
        "\n",
        "OUTPUT_FILE = \"edgar_gt_combined_extracted.csv\"\n",
        "BATCH_SIZE = 10  # Save checkpoint every N documents\n",
        "MAX_DOCUMENTS = 250  # Total documents to process\n",
        "\n",
        "# Sampling parameters for deterministic output\n",
        "SAMPLING_PARAMS = SamplingParams(\n",
        "    temperature=0.0,\n",
        "    max_tokens=500,\n",
        "    stop=[\"}\"],  # Stop after JSON closes\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5. Question Bank (All 8 Fields)\n",
        "\n",
        "QUESTION_BANK = [\n",
        "    {\n",
        "        \"id\": \"registrant_name\",\n",
        "        \"prompt\": (\n",
        "            \"What is the exact legal name of the registrant as explicitly stated in the document? \"\n",
        "            \"Return ONLY the legal name string or NOT_FOUND.\"\n",
        "        ),\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"headquarters_city\",\n",
        "        \"prompt\": (\n",
        "            \"What city is explicitly stated as the location of the registrant's principal executive offices? \"\n",
        "            \"Return ONLY the city name or NOT_FOUND.\"\n",
        "        ),\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"headquarters_state\",\n",
        "        \"prompt\": (\n",
        "            \"What U.S. state is explicitly stated as the location of the registrant's principal executive offices? \"\n",
        "            \"Return ONLY the state name or NOT_FOUND.\"\n",
        "        ),\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"incorporation_state\",\n",
        "        \"prompt\": (\n",
        "            \"What is the registrant's state of incorporation as explicitly stated in the document? \"\n",
        "            \"Return ONLY the state name or NOT_FOUND.\"\n",
        "        ),\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"incorporation_year\",\n",
        "        \"prompt\": (\n",
        "            \"What is the registrant's year of incorporation as explicitly stated in the document? \"\n",
        "            \"Return ONLY the year (YYYY) or NOT_FOUND.\"\n",
        "        ),\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"employee_count\",\n",
        "        \"prompt\": (\n",
        "            \"What is the number of employees that the registrant has as explicitly stated in the document? \"\n",
        "            \"Return ONLY the integer (remove commas) or NOT_FOUND.\"\n",
        "        ),\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"ceo_lastname\",\n",
        "        \"prompt\": (\n",
        "            \"What is the last name of the individual explicitly identified as the Chief Executive Officer (CEO) of the registrant as explicitly stated in the document? \"\n",
        "            \"Return ONLY the last name string or NOT_FOUND.\"\n",
        "        ),\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"holder_record_amount\",\n",
        "        \"prompt\": (\n",
        "            \"What is the number of holders of record of the registrant's common stock as explicitly stated in the document? \"\n",
        "            \"Return ONLY the integer (remove commas) or NOT_FOUND.\"\n",
        "        ),\n",
        "    },\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 6. Full Context Builder (Concatenates ALL Sections)\n",
        "\n",
        "SECTION_KEYS = [\n",
        "    \"section_1\", \"section_1A\", \"section_1B\", \"section_2\", \"section_3\",\n",
        "    \"section_4\", \"section_5\", \"section_6\", \"section_7\", \"section_7A\",\n",
        "    \"section_8\", \"section_9\", \"section_9A\", \"section_9B\", \"section_10\",\n",
        "    \"section_11\", \"section_12\", \"section_13\", \"section_14\", \"section_15\"\n",
        "]\n",
        "\n",
        "def build_full_context(doc):\n",
        "    \"\"\"\n",
        "    Concatenates ALL available sections from the 10-K filing.\n",
        "    Returns the full text with section headers for context.\n",
        "    \"\"\"\n",
        "    parts = []\n",
        "    for key in SECTION_KEYS:\n",
        "        section_text = doc.get(key, \"\")\n",
        "        if section_text and section_text.strip():\n",
        "            parts.append(f\"\\n\\n--- [{key.upper()}] ---\\n\\n{section_text}\")\n",
        "    \n",
        "    return \"\".join(parts) if parts else \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 7. Extraction Prompt Template\n",
        "\n",
        "EXTRACTION_TEMPLATE = \"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
        "\n",
        "You are a precise SEC 10-K filing data extraction assistant. You MUST:\n",
        "1. Extract information ONLY from the provided text.\n",
        "2. If the information is not found, return \"NOT_FOUND\" as the value, and for evidence provide your reasoning on why it was not found.\n",
        "3. Always provide the exact quote from the text as evidence. \n",
        "4. Respond ONLY with valid JSON, nothing else.\n",
        "\n",
        "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
        "\n",
        "Read this SEC 10-K filing and answer the question.\n",
        "\n",
        "**Question**: {question}\n",
        "\n",
        "**Instructions**:\n",
        "- Provide your answer as a JSON object with exactly these keys:\n",
        "  - \"value\": The extracted answer (or \"NOT_FOUND\" if not present)\n",
        "  - \"evidence\": If value is found, the EXACT substring from the text. If NOT_FOUND, explain WHY it could not be found.\n",
        "  - \"source_sentence\": The complete sentence containing the evidence (or \"N/A\" if NOT_FOUND)\n",
        "\n",
        "**10-K Filing Text**:\n",
        "{context}\n",
        "\n",
        "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
        "\n",
        "{{\"\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 8. LLM Extraction Function\n",
        "\n",
        "def extract_field(full_text, question_config, llm, sampling_params):\n",
        "    \"\"\"\n",
        "    Extracts a single field from the full text using the LLM.\n",
        "    Returns: (value, evidence, source_sentence)\n",
        "    \"\"\"\n",
        "    if not full_text or not full_text.strip():\n",
        "        return \"NOT_FOUND\", \"NO_CONTEXT\", \"NO_CONTEXT\"\n",
        "    \n",
        "    prompt = EXTRACTION_TEMPLATE.format(\n",
        "        question=question_config[\"prompt\"],\n",
        "        context=full_text\n",
        "    )\n",
        "    \n",
        "    # Generate with vLLM\n",
        "    outputs = llm.generate([prompt], sampling_params)\n",
        "    response_text = outputs[0].outputs[0].text.strip()\n",
        "    \n",
        "    # Parse JSON response\n",
        "    try:\n",
        "        # The response starts after we injected '{\"', so prepend it back\n",
        "        json_str = '{\"' + response_text\n",
        "        if not json_str.endswith('}'):\n",
        "            json_str += '}'\n",
        "        \n",
        "        data = json.loads(json_str)\n",
        "        value = data.get(\"value\", \"PARSE_ERROR\")\n",
        "        evidence = data.get(\"evidence\", \"PARSE_ERROR\")\n",
        "        source_sentence = data.get(\"source_sentence\", \"PARSE_ERROR\")\n",
        "        \n",
        "        # Clean up value\n",
        "        if value:\n",
        "            value = str(value).strip().rstrip('.')\n",
        "        \n",
        "        return value, evidence, source_sentence\n",
        "        \n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"  [JSON ERROR] {question_config['id']}: {e}\")\n",
        "        print(f\"  Raw response: {response_text[:200]}...\")\n",
        "        return \"JSON_PARSE_ERROR\", response_text[:500], \"JSON_PARSE_ERROR\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 9. Evidence Verification (\"Judge\" Logic)\n",
        "\n",
        "def get_fingerprint(text):\n",
        "    \"\"\"Removes all non-alphanumeric characters for fuzzy matching.\"\"\"\n",
        "    return re.sub(r'[\\W_]+', '', text).lower()\n",
        "\n",
        "def verify_evidence(full_text, evidence_quote, value):\n",
        "    \"\"\"\n",
        "    Checks if the evidence quote actually exists in the full text.\n",
        "    Returns: \n",
        "        - True if verified (evidence found in text)\n",
        "        - False if not found (potential hallucination)\n",
        "        - \"NOT_APPLICABLE\" if value was NOT_FOUND (evidence is reasoning, not a quote)\n",
        "    \"\"\"\n",
        "    # If value is NOT_FOUND, evidence is reasoning - don't try to verify it exists\n",
        "    if value and str(value).upper() == \"NOT_FOUND\":\n",
        "        return \"NOT_APPLICABLE\"\n",
        "    \n",
        "    if not evidence_quote or evidence_quote in [\"NO_CONTEXT\", \"PARSE_ERROR\", \"JSON_PARSE_ERROR\", \"N/A\"]:\n",
        "        return None  # Missing data\n",
        "    \n",
        "    if not full_text:\n",
        "        return False\n",
        "    \n",
        "    # 1. Exact match\n",
        "    if evidence_quote in full_text:\n",
        "        return True\n",
        "    \n",
        "    # 2. Normalized match (ignore whitespace/punctuation differences)\n",
        "    clean_text = \" \".join(full_text.split()).lower()\n",
        "    clean_evd = \" \".join(evidence_quote.split()).lower()\n",
        "    \n",
        "    if clean_evd in clean_text:\n",
        "        return True\n",
        "    \n",
        "    # 3. Fingerprint match (ignore all punctuation)\n",
        "    fp_text = get_fingerprint(full_text)\n",
        "    fp_evd = get_fingerprint(evidence_quote)\n",
        "    \n",
        "    if len(fp_evd) > 10 and fp_evd in fp_text:\n",
        "        return True\n",
        "    \n",
        "    return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 10. Load Dataset (from existing notebook pattern)\n",
        "\n",
        "def load_edgar_dataset():\n",
        "    \"\"\"Load the EDGAR corpus with streaming.\"\"\"\n",
        "    return load_dataset(\n",
        "        \"c3po-ai/edgar-corpus\",\n",
        "        \"default\",\n",
        "        split=\"train\",\n",
        "        streaming=True,\n",
        "        revision=\"refs/convert/parquet\",\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 11. Process Single Document\n",
        "\n",
        "def process_document(doc, llm, sampling_params):\n",
        "    \"\"\"\n",
        "    Extracts all 8 fields from a single document.\n",
        "    Returns a dict with all columns for the output CSV.\n",
        "    \"\"\"\n",
        "    result = {\n",
        "        \"filename\": doc.get(\"filename\"),\n",
        "        \"cik\": doc.get(\"cik\"),\n",
        "        \"year\": doc.get(\"year\"),\n",
        "    }\n",
        "    \n",
        "    # Build full context once\n",
        "    full_text = build_full_context(doc)\n",
        "    result[\"full_text\"] = full_text  # Store for manual review\n",
        "    \n",
        "    if not full_text:\n",
        "        # No content - mark all fields as not found\n",
        "        for q in QUESTION_BANK:\n",
        "            field_id = q[\"id\"]\n",
        "            result[f\"{field_id}_value\"] = \"NO_CONTENT\"\n",
        "            result[f\"{field_id}_evidence\"] = \"NO_CONTENT\"\n",
        "            result[f\"{field_id}_source_sentence\"] = \"NO_CONTENT\"\n",
        "            result[f\"{field_id}_evidence_verified\"] = None\n",
        "        return result\n",
        "    \n",
        "    # Extract each field\n",
        "    for question in QUESTION_BANK:\n",
        "        field_id = question[\"id\"]\n",
        "        \n",
        "        value, evidence, source_sentence = extract_field(\n",
        "            full_text, question, llm, sampling_params\n",
        "        )\n",
        "        \n",
        "        # Verify evidence exists in text\n",
        "        evidence_verified = verify_evidence(full_text, evidence, value)\n",
        "        \n",
        "        result[f\"{field_id}_value\"] = value\n",
        "        result[f\"{field_id}_evidence\"] = evidence\n",
        "        result[f\"{field_id}_source_sentence\"] = source_sentence\n",
        "        result[f\"{field_id}_evidence_verified\"] = evidence_verified\n",
        "    \n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 12. Main Extraction Loop\n",
        "\n",
        "def run_extraction(\n",
        "    output_file=OUTPUT_FILE,\n",
        "    limit=MAX_DOCUMENTS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "):\n",
        "    \"\"\"\n",
        "    Main extraction loop with resume support and batch checkpointing.\n",
        "    \"\"\"\n",
        "    print(f\"--- COMBINED EXTRACTION: {limit} documents ---\")\n",
        "    \n",
        "    # 1. Resume support: Load existing progress\n",
        "    if os.path.exists(output_file):\n",
        "        df_results = pd.read_csv(output_file)\n",
        "        processed_files = set(df_results[\"filename\"].tolist())\n",
        "        print(f\"Resuming: {len(processed_files)} documents already processed.\")\n",
        "    else:\n",
        "        df_results = pd.DataFrame()\n",
        "        processed_files = set()\n",
        "    \n",
        "    # 2. Load dataset\n",
        "    dataset = load_edgar_dataset()\n",
        "    \n",
        "    current_batch = []\n",
        "    total_processed = len(processed_files)\n",
        "    new_processed = 0\n",
        "    \n",
        "    # 3. Main loop\n",
        "    for doc in tqdm(dataset, desc=\"Extracting\", total=limit):\n",
        "        fname = doc.get(\"filename\")\n",
        "        \n",
        "        # Skip if already processed\n",
        "        if fname in processed_files:\n",
        "            continue\n",
        "        \n",
        "        # Limit check\n",
        "        if total_processed + new_processed >= limit:\n",
        "            break\n",
        "        \n",
        "        # Process document\n",
        "        result = process_document(doc, llm, SAMPLING_PARAMS)\n",
        "        current_batch.append(result)\n",
        "        new_processed += 1\n",
        "        \n",
        "        # Batch checkpoint\n",
        "        if len(current_batch) >= batch_size:\n",
        "            df_batch = pd.DataFrame(current_batch)\n",
        "            df_results = pd.concat([df_results, df_batch], ignore_index=True)\n",
        "            df_results.to_csv(output_file, index=False)\n",
        "            current_batch = []\n",
        "            \n",
        "            # Memory cleanup\n",
        "            gc.collect()\n",
        "            torch.cuda.empty_cache()\n",
        "            print(f\"  [Checkpoint] Saved {total_processed + new_processed}/{limit} docs.\")\n",
        "    \n",
        "    # 4. Final save\n",
        "    if current_batch:\n",
        "        df_batch = pd.DataFrame(current_batch)\n",
        "        df_results = pd.concat([df_results, df_batch], ignore_index=True)\n",
        "        df_results.to_csv(output_file, index=False)\n",
        "    \n",
        "    print(f\"--- EXTRACTION COMPLETE: {output_file} ---\")\n",
        "    return df_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 13. Run Extraction\n",
        "\n",
        "df_extracted = run_extraction(\n",
        "    output_file=OUTPUT_FILE,\n",
        "    limit=MAX_DOCUMENTS,\n",
        "    batch_size=BATCH_SIZE,\n",
        ")\n",
        "\n",
        "# Display sample results\n",
        "print(f\"\\nTotal rows: {len(df_extracted)}\")\n",
        "display(df_extracted.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 14. Quality Report\n",
        "\n",
        "def generate_quality_report(df):\n",
        "    \"\"\"Generate a summary of extraction quality.\"\"\"\n",
        "    print(\"\\n=== EXTRACTION QUALITY REPORT ===\")\n",
        "    print(f\"Total documents: {len(df)}\")\n",
        "    print()\n",
        "    \n",
        "    for q in QUESTION_BANK:\n",
        "        field_id = q[\"id\"]\n",
        "        value_col = f\"{field_id}_value\"\n",
        "        verified_col = f\"{field_id}_evidence_verified\"\n",
        "        \n",
        "        if value_col not in df.columns:\n",
        "            continue\n",
        "        \n",
        "        total = len(df)\n",
        "        found = len(df[~df[value_col].isin([\"NOT_FOUND\", \"NO_CONTENT\", \"JSON_PARSE_ERROR\"])])\n",
        "        if verified_col in df.columns:\n",
        "            verified = df[verified_col].sum() if df[verified_col].dtype == bool else 0\n",
        "        else:\n",
        "            verified = \"N/A\"\n",
        "        \n",
        "        print(f\"{field_id}:\")\n",
        "        print(f\"  Found: {found}/{total} ({100*found/total:.1f}%)\")\n",
        "        print(f\"  Evidence Verified: {verified}\")\n",
        "        print()\n",
        "\n",
        "if not df_extracted.empty:\n",
        "    generate_quality_report(df_extracted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 15. Inspect Specific Results (by row number)\n",
        "\n",
        "ROW_NUMBER = 0  # Change this to inspect different rows\n",
        "\n",
        "if not df_extracted.empty and ROW_NUMBER < len(df_extracted):\n",
        "    row = df_extracted.iloc[ROW_NUMBER]\n",
        "    \n",
        "    print(f\"=== ROW {ROW_NUMBER}: {row['filename']} ===\")\n",
        "    print(f\"CIK: {row['cik']} | Year: {row['year']}\")\n",
        "    print()\n",
        "    \n",
        "    for q in QUESTION_BANK:\n",
        "        field_id = q[\"id\"]\n",
        "        print(f\"--- {field_id} ---\")\n",
        "        print(f\"  Value: {row[f'{field_id}_value']}\")\n",
        "        print(f\"  Evidence: {row[f'{field_id}_evidence']}\")\n",
        "        print(f\"  Verified: {row[f'{field_id}_evidence_verified']}\")\n",
        "        print()\n",
        "else:\n",
        "    print(f\"Row {ROW_NUMBER} not found. DataFrame has {len(df_extracted)} rows.\")# 15. Inspect Specific Results (Optional)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "ROW_TO_INSPECT = 0  # Change this to view different rows\n",
        "if not df_extracted.empty and ROW_TO_INSPECT < len(df_extracted):\n",
        "    row = df_extracted.iloc[ROW_TO_INSPECT]\n",
        "    \n",
        "    print(f\"=== FULL TEXT: {row['filename']} ===\")\n",
        "    print(f\"Length: {len(row['full_text'])} characters\")\n",
        "    print(\"=\" * 60)\n",
        "    print(row['full_text'])\n",
        "else:\n",
        "    print(f\"Row {ROW_TO_INSPECT} not found.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def split_combined_df_by_feature(\n",
        "    df,\n",
        "    output_dir=\"./split_features/\",\n",
        "    id_columns=None,\n",
        "):\n",
        "    \"\"\"\n",
        "    Split a combined extraction DataFrame into separate CSVs per feature.\n",
        "    \n",
        "    Args:\n",
        "        df: The master DataFrame containing all features.\n",
        "        output_dir: Directory to save the split CSV files.\n",
        "        id_columns: List of identity columns to keep in each file.\n",
        "                    Default: [\"filename\", \"cik\", \"year\"]\n",
        "    \n",
        "    Returns:\n",
        "        Dict mapping feature_id -> output file path.\n",
        "    \n",
        "    Example Output Files:\n",
        "        - split_features/extracted_registrant_name.csv\n",
        "        - split_features/extracted_employee_count.csv\n",
        "        - ...\n",
        "    \"\"\"\n",
        "    if id_columns is None:\n",
        "        id_columns = [\"filename\", \"cik\", \"year\"]\n",
        "    \n",
        "    # Create output directory if needed\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    \n",
        "    # Discover which features are in the DataFrame\n",
        "    # Pattern: {feature_id}_value, {feature_id}_evidence, etc.\n",
        "    feature_ids = set()\n",
        "    for col in df.columns:\n",
        "        if col.endswith(\"_value\"):\n",
        "            feature_id = col.replace(\"_value\", \"\")\n",
        "            feature_ids.add(feature_id)\n",
        "    \n",
        "    if not feature_ids:\n",
        "        print(\"No feature columns found in DataFrame. Looking for *_value columns.\")\n",
        "        return {}\n",
        "    \n",
        "    print(f\"Found {len(feature_ids)} features to split: {sorted(feature_ids)}\")\n",
        "    \n",
        "    output_files = {}\n",
        "    \n",
        "    for feature_id in sorted(feature_ids):\n",
        "        # Define column patterns for this feature\n",
        "        feature_cols = [\n",
        "            f\"{feature_id}_value\",\n",
        "            f\"{feature_id}_evidence\",\n",
        "            f\"{feature_id}_source_sentence\",\n",
        "            f\"{feature_id}_evidence_verified\",\n",
        "        ]\n",
        "        \n",
        "        # Filter to columns that actually exist\n",
        "        existing_feature_cols = [c for c in feature_cols if c in df.columns]\n",
        "        \n",
        "        if not existing_feature_cols:\n",
        "            print(f\"  [SKIP] {feature_id}: No columns found.\")\n",
        "            continue\n",
        "        \n",
        "        # Select identity + feature columns\n",
        "        cols_to_keep = [c for c in id_columns if c in df.columns] + existing_feature_cols\n",
        "        \n",
        "        df_feature = df[cols_to_keep].copy()\n",
        "        \n",
        "        # Output path\n",
        "        output_path = os.path.join(output_dir, f\"extracted_{feature_id}.csv\")\n",
        "        \n",
        "        df_feature.to_csv(output_path, index=False)\n",
        "        output_files[feature_id] = output_path\n",
        "        \n",
        "        # Summary\n",
        "        value_col = f\"{feature_id}_value\"\n",
        "        total_rows = len(df_feature)\n",
        "        found_count = len(df_feature[~df_feature[value_col].isin([\"NOT_FOUND\", \"NO_CONTENT\", \"JSON_PARSE_ERROR\", None])])\n",
        "        \n",
        "        print(f\"  âœ“ {feature_id}: {output_path}\")\n",
        "        print(f\"      Rows: {total_rows} | Found: {found_count} ({100*found_count/total_rows:.1f}%)\")\n",
        "    \n",
        "    print(f\"\\n--- SPLIT COMPLETE: {len(output_files)} files written to {output_dir} ---\")\n",
        "    return output_files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Split Combined DataFrame ---\n",
        "# After running full extraction, split into separate files:\n",
        "#\n",
        "if not df_extracted.empty:\n",
        "    output_paths = split_combined_df_by_feature(\n",
        "        df=df_extracted,\n",
        "        output_dir=\"./split_features/\",\n",
        "    )\n",
        "    print(output_paths)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# EDGAR Ground Truth Singular Extraction (Full Context)\n",
        "\n",
        "**Goal**: Extract 1 field from SEC 10-K filings with evidence provenance (using all sections this time).\n",
        "\n",
        "**Model**: Llama 3.3 70B Instruct via vLLM on Lambda GPU\n",
        "\n",
        "**Strategy**: Per-field sequential extraction with JSON structured output.\n",
        "\n",
        "**Output**: CSV with `{field}_value`, `{field}_evidence`, `{field}_source_sentence`, `{field}_evidence_verified` the field."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# **Purpose**: Extract a single feature from QUESTION_BANK to a CSV, with \n",
        "# append/merge support like `discover_new_feature` in the single notebook.\n",
        "#\n",
        "# Uses the existing vLLM setup (llm, SAMPLING_PARAMS) from this notebook.\n",
        "# ==============================================================================\n",
        "\n",
        "def merge_and_save_to_csv(df_master, batch_data, output_path):\n",
        "    \"\"\"\n",
        "    Merge new feature columns into existing master DataFrame.\n",
        "    - If filename exists: Add/update the feature columns for that row.\n",
        "    - If filename is new: Append the entire row.\n",
        "    \n",
        "    Adapted from extract_edgar_gt_single.ipynb's merge_and_save.\n",
        "    \"\"\"\n",
        "    df_batch = pd.DataFrame(batch_data)\n",
        "    \n",
        "    if df_master.empty:\n",
        "        df_master = df_batch\n",
        "    else:\n",
        "        # Normalize merge key to string\n",
        "        df_master[\"filename\"] = df_master[\"filename\"].astype(str)\n",
        "        df_batch[\"filename\"] = df_batch[\"filename\"].astype(str)\n",
        "        \n",
        "        # Drop identity columns from batch to prevent duplicates\n",
        "        batch_feature_cols = [col for col in df_batch.columns if col not in [\"filename\", \"cik\", \"year\"]]\n",
        "        df_batch_slim = df_batch[[\"filename\"] + batch_feature_cols]\n",
        "        \n",
        "        # Merge on filename (outer join to add new filenames)\n",
        "        df_master = pd.merge(\n",
        "            df_master,\n",
        "            df_batch_slim,\n",
        "            on=\"filename\",\n",
        "            how=\"outer\",\n",
        "            suffixes=(\"\", \"_new\")\n",
        "        )\n",
        "        \n",
        "        # Fill in cik/year for new rows\n",
        "        new_rows_mask = df_master[\"cik\"].isna()\n",
        "        if new_rows_mask.any():\n",
        "            batch_identity = df_batch.set_index(\"filename\")[[\"cik\", \"year\"]]\n",
        "            for idx in df_master[new_rows_mask].index:\n",
        "                fname = df_master.at[idx, \"filename\"]\n",
        "                if fname in batch_identity.index:\n",
        "                    df_master.at[idx, \"cik\"] = batch_identity.at[fname, \"cik\"]\n",
        "                    df_master.at[idx, \"year\"] = batch_identity.at[fname, \"year\"]\n",
        "        \n",
        "        # Cleanup duplicate columns (e.g., 'value_new' -> merge into 'value')\n",
        "        for col in list(df_master.columns):\n",
        "            if col.endswith(\"_new\"):\n",
        "                base_col = col.replace(\"_new\", \"\")\n",
        "                if base_col in df_master.columns:\n",
        "                    df_master[base_col] = df_master[base_col].fillna(df_master[col])\n",
        "                else:\n",
        "                    df_master.rename(columns={col: base_col}, inplace=True)\n",
        "                if col in df_master.columns:\n",
        "                    df_master.drop(columns=[col], inplace=True)\n",
        "    \n",
        "    df_master.to_csv(output_path, index=False)\n",
        "    return df_master\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def run_single_feature_extraction(\n",
        "    feature_id,\n",
        "    output_file=\"single_feature_extracted.csv\",\n",
        "    limit=MAX_DOCUMENTS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "):\n",
        "    \"\"\"\n",
        "    Extract a SINGLE feature from QUESTION_BANK using vLLM.\n",
        "    \n",
        "    Supports:\n",
        "    - **Resume**: Skips documents already processed for this feature.\n",
        "    - **Merge**: If file exists with other features, adds new columns.\n",
        "    - **Append**: If file exists but new documents are processed, appends rows.\n",
        "    \n",
        "    Args:\n",
        "        feature_id: The 'id' of the question in QUESTION_BANK to extract.\n",
        "        output_file: Path to the output CSV (will be created or merged into).\n",
        "        limit: Maximum number of documents to process.\n",
        "        batch_size: Checkpoint interval (saves every N docs).\n",
        "    \n",
        "    Returns:\n",
        "        DataFrame with extraction results.\n",
        "    \"\"\"\n",
        "    print(f\"--- SINGLE FEATURE EXTRACTION: {feature_id} ---\")\n",
        "    \n",
        "    # 1. Validate feature_id exists in QUESTION_BANK\n",
        "    question_config = None\n",
        "    for q in QUESTION_BANK:\n",
        "        if q[\"id\"] == feature_id:\n",
        "            question_config = q\n",
        "            break\n",
        "    \n",
        "    if question_config is None:\n",
        "        raise ValueError(f\"Feature '{feature_id}' not found in QUESTION_BANK. Available: {[q['id'] for q in QUESTION_BANK]}\")\n",
        "    \n",
        "    print(f\"  Question: {question_config['prompt'][:80]}...\")\n",
        "    \n",
        "    # 2. Column names for this feature\n",
        "    value_col = f\"{feature_id}_value\"\n",
        "    evidence_col = f\"{feature_id}_evidence\"\n",
        "    source_col = f\"{feature_id}_source_sentence\"\n",
        "    verified_col = f\"{feature_id}_evidence_verified\"\n",
        "    \n",
        "    # 3. Load existing progress (resume support)\n",
        "    if os.path.exists(output_file):\n",
        "        df_master = pd.read_csv(output_file)\n",
        "        # Check if this feature has already been processed for some docs\n",
        "        if value_col in df_master.columns:\n",
        "            processed_files = set(\n",
        "                df_master[df_master[value_col].notna()][\"filename\"].tolist()\n",
        "            )\n",
        "            print(f\"  Resuming: {len(processed_files)} documents already have '{feature_id}'.\")\n",
        "        else:\n",
        "            processed_files = set()\n",
        "            print(f\"  File exists, but '{feature_id}' is a NEW feature. Will merge columns.\")\n",
        "    else:\n",
        "        df_master = pd.DataFrame()\n",
        "        processed_files = set()\n",
        "        print(f\"  Starting fresh extraction.\")\n",
        "    \n",
        "    # 4. Load dataset\n",
        "    dataset = load_edgar_dataset()\n",
        "    \n",
        "    current_batch = []\n",
        "    total_processed = len(processed_files)\n",
        "    new_processed = 0\n",
        "    \n",
        "    # 5. Main extraction loop\n",
        "    for doc in tqdm(dataset, desc=f\"Extracting {feature_id}\", total=limit):\n",
        "        fname = doc.get(\"filename\")\n",
        "        \n",
        "        # Skip if already processed\n",
        "        if fname in processed_files:\n",
        "            continue\n",
        "        \n",
        "        # Limit check\n",
        "        if total_processed + new_processed >= limit:\n",
        "            break\n",
        "        \n",
        "        # Build full context\n",
        "        full_text = build_full_context(doc)\n",
        "        \n",
        "        # Extract this single field\n",
        "        value, evidence, source_sentence = extract_field(\n",
        "            full_text, question_config, llm, SAMPLING_PARAMS\n",
        "        )\n",
        "        \n",
        "        # Verify evidence\n",
        "        evidence_verified = verify_evidence(full_text, evidence, value)\n",
        "        \n",
        "        # Build result row\n",
        "        row = {\n",
        "            \"filename\": fname,\n",
        "            \"cik\": doc.get(\"cik\"),\n",
        "            \"year\": doc.get(\"year\"),\n",
        "            value_col: value,\n",
        "            evidence_col: evidence,\n",
        "            source_col: source_sentence,\n",
        "            verified_col: evidence_verified,\n",
        "        }\n",
        "        \n",
        "        current_batch.append(row)\n",
        "        new_processed += 1\n",
        "        \n",
        "        # Batch checkpoint\n",
        "        if len(current_batch) >= batch_size:\n",
        "            df_master = merge_and_save_to_csv(df_master, current_batch, output_file)\n",
        "            current_batch = []\n",
        "            \n",
        "            gc.collect()\n",
        "            torch.cuda.empty_cache()\n",
        "            print(f\"  [Checkpoint] Saved {total_processed + new_processed}/{limit} docs.\")\n",
        "    \n",
        "    # 6. Final save\n",
        "    if current_batch:\n",
        "        df_master = merge_and_save_to_csv(df_master, current_batch, output_file)\n",
        "    \n",
        "    print(f\"--- SINGLE FEATURE EXTRACTION COMPLETE: {output_file} ---\")\n",
        "    print(f\"  Total documents with '{feature_id}': {len(df_master[df_master[value_col].notna()]) if value_col in df_master.columns else 0}\")\n",
        "    \n",
        "    return df_master"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Single Feature Extraction ---\n",
        "# Extract ONLY 'employee_count' to a file (with merge/append support):\n",
        "#\n",
        "df_single = run_single_feature_extraction(\n",
        "    feature_id=\"employee_count\",\n",
        "    output_file=\"employee_count_only.csv\",\n",
        "    limit=100,\n",
        "    batch_size=10,\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
