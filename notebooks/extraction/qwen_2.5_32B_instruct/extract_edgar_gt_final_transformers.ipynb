{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# EDGAR Ground Truth Combined Extraction (Full Context)\n",
        "\n",
        "**Goal**: Extract all 8 fields from SEC 10-K filings with evidence provenance.\n",
        "\n",
        "**Model**: Qwen 2.5 32B Instruct via **Transformers** (HuggingFace)\n",
        "\n",
        "**Strategy**: Per-field sequential extraction with JSON structured output.\n",
        "\n",
        "**Output**: CSV with `{field}_value`, `{field}_evidence`, `{field}_source_sentence`, `{field}_evidence_verified` for each field."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Installation (Run once on Lambda) \n",
        "#%env HF_TOKEN=your_token\n",
        "#!pip install -q datasets pandas tqdm thefuzz python-Levenshtein transformers huggingface_hub accelerate bitsandbytes "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2. Imports & Setup\n",
        "import os\n",
        "import re\n",
        "import gc\n",
        "import json\n",
        "import pandas as pd\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, logging, BitsAndBytesConfig\n",
        "from huggingface_hub import login \n",
        "\n",
        "logging.set_verbosity_error()\n",
        "pd.set_option('display.max_colwidth', None) \n",
        "login(token=os.environ[\"HF_TOKEN\"]) # or login(token=\"your_token\")\n",
        "print(\"Setup Complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3. Load Model (Qwen 2.5 32B Instruct via Transformers)\n",
        "\n",
        "MODEL_NAME = \"qwen/Qwen-2.5-32B-Instruct\"\n",
        "DTYPE = torch.bfloat16\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "quantization_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_type=torch.bfloat16,\n",
        ")\n",
        "\n",
        "print(f\"Loading {MODEL_NAME} via Transformers...\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME, \n",
        "    quantization_config=quantization_config,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "model.eval()\n",
        "\n",
        "print(f\"Model loaded on {torch.cuda.device_count()} GPU(s). Device: {DEVICE}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4. Configuration\n",
        "\n",
        "OUTPUT_FILE = \"edgar_gt_combined_extracted.csv\"\n",
        "BATCH_SIZE = 10  # Save checkpoint every N documents\n",
        "MAX_DOCUMENTS = 250  # Total documents to process\n",
        "USE_BATCH_MODE = False  # True = one prompt for all fields\n",
        "\n",
        "# Generation parameters for deterministic output (replaces SamplingParams)\n",
        "GENERATION_CONFIG = {\n",
        "    \"max_new_tokens\": 500,\n",
        "    \"do_sample\": False,\n",
        "    \"temperature\": None,  # Greedy decoding when do_sample=False\n",
        "    \"pad_token_id\": tokenizer.pad_token_id,\n",
        "    \"eos_token_id\": tokenizer.eos_token_id,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5. Question Bank (All Fields)\n",
        "\n",
        "QUESTION_BANK = [\n",
        "    {\n",
        "        \"id\": \"registrant_name\",\n",
        "        \"prompt\": (\n",
        "            \"What is the exact legal name of the registrant as explicitly stated in the document? \"\n",
        "            \"Return ONLY the legal name string or NOT_FOUND.\"\n",
        "        ),\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"headquarters_city\",\n",
        "        \"prompt\": (\n",
        "            \"What city is explicitly stated as the location of the registrant's principal executive offices? \"\n",
        "            \"Return ONLY the city name or NOT_FOUND.\"\n",
        "        ),\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"headquarters_state\",\n",
        "        \"prompt\": (\n",
        "            \"What U.S. state is explicitly stated as the location of the registrant's principal executive offices? \"\n",
        "            \"Return ONLY the state name or NOT_FOUND.\"\n",
        "        ),\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"incorporation_state\",\n",
        "        \"prompt\": (\n",
        "            \"Identify the state or other jurisdiction under the laws of which the registrant is **currently** organized or incorporated. \"\n",
        "            \"Exclude former jurisdictions. \"\n",
        "            \"Return ONLY the state name or NOT_FOUND.\"\n",
        "        ),\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"incorporation_year\",\n",
        "        \"prompt\": (\n",
        "            \"What is the year of the registrant's incorporation in its **current** jurisdiction (state of incorporation)? \"\n",
        "            \"Return ONLY the year (YYYY) or NOT_FOUND.\"\n",
        "        ),\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"employees_count_total\",\n",
        "        \"prompt\": (\n",
        "            \"What is the **total** number of persons employed by the registrant? \"\n",
        "            \"Include full-time and part-time employees. \"\n",
        "            \"Return ONLY the integer (remove commas) or NOT_FOUND.\"\n",
        "        ),\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"employees_count_full_time\",\n",
        "        \"prompt\": (\n",
        "            \"What is the number of **full-time** employees explicitly stated? \"\n",
        "            \"Return ONLY the integer (remove commas) or NOT_FOUND.\"\n",
        "        ),\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"irs_tax_id\",\n",
        "        \"prompt\": (\n",
        "            \"What is the IRS Employer Identification Number (EIN) or I.R.S. Employer Identification No. of the registrant? \"\n",
        "            \"Return ONLY the number (format XX-XXXXXXX) or NOT_FOUND.\"\n",
        "        ),\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"ceo_lastname\",\n",
        "        \"prompt\": (\n",
        "            \"What is the last name of the individual explicitly identified as the Chief Executive Officer (CEO) of the registrant as explicitly stated in the document? \"\n",
        "            \"Return ONLY the last name string or NOT_FOUND.\"\n",
        "        ),\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"holder_record_amount\",\n",
        "        \"prompt\": (\n",
        "            \"What is the number of holders of record of the registrant's common stock as explicitly stated in the document? \"\n",
        "            \"Return ONLY the integer (remove commas) or NOT_FOUND.\"\n",
        "        ),\n",
        "    },\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 6. Full Context Builder (Concatenates ALL Sections)\n",
        "\n",
        "SECTION_KEYS = [\n",
        "    \"section_1\", \"section_1A\", \"section_1B\", \"section_2\", \"section_3\",\n",
        "    \"section_4\", \"section_5\", \"section_6\", \"section_7\", \"section_7A\",\n",
        "    \"section_8\", \"section_9\", \"section_9A\", \"section_9B\", \"section_10\",\n",
        "    \"section_11\", \"section_12\", \"section_13\", \"section_14\", \"section_15\"\n",
        "]\n",
        "TEXT_COLUMNS = [\"full_text\"] + SECTION_KEYS\n",
        "\n",
        "def build_full_context(doc):\n",
        "    \"\"\"\n",
        "    Concatenates ALL available sections from the 10-K filing.\n",
        "    Returns the full text with section headers for context.\n",
        "    \"\"\"\n",
        "    parts = []\n",
        "    for key in SECTION_KEYS:\n",
        "        section_text = doc.get(key, \"\")\n",
        "        if section_text and section_text.strip():\n",
        "            parts.append(f\"\\n\\n--- [{key.upper()}] ---\\n\\n{section_text}\")\n",
        "    \n",
        "    return \"\".join(parts) if parts else \"\"\n",
        "def fill_missing_text_columns(df):\n",
        "    \"\"\"Fill missing text columns to avoid NaNs in CSVs.\"\"\"\n",
        "    for col in TEXT_COLUMNS:\n",
        "        if col in df.columns:\n",
        "            df[col] = df[col].fillna(\"\")\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 7. Extraction Prompt Template (Using Llama 3 chat format via apply_chat_template)\n",
        "\n",
        "SYSTEM_PROMPT = \"\"\"You are a precise SEC 10-K filing data extraction assistant. You MUST:\n",
        "1. Extract information ONLY from the provided text.\n",
        "2. If the information is not found, return \"NOT_FOUND\" as the value, and for evidence provide your reasoning on why it was not found.\n",
        "3. Always provide the exact quote from the text as evidence. \n",
        "4. Respond ONLY with valid JSON, nothing else.\"\"\"\n",
        "\n",
        "USER_TEMPLATE = \"\"\"Read this SEC 10-K filing and answer the question.\n",
        "\n",
        "**Question**: {question}\n",
        "\n",
        "**Instructions**:\n",
        "- Provide your answer as a JSON object with exactly these keys:\n",
        "  - \"value\": The extracted answer (or \"NOT_FOUND\" if not present)\n",
        "  - \"evidence\": If value is found, the EXACT substring from the text. If NOT_FOUND, explain WHY it could not be found.\n",
        "  - \"source_sentence\": The complete sentence containing the evidence (or \"N/A\" if NOT_FOUND)\n",
        "\n",
        "**10-K Filing Text**:\n",
        "{context}\"\"\"\n",
        "\n",
        "BATCH_USER_TEMPLATE = \"\"\"Read this SEC 10-K filing and extract ALL of the fields listed below.\n",
        "\n",
        "**Fields to Extract**:\n",
        "{questions}\n",
        "\n",
        "**Instructions**:\n",
        "- Return a SINGLE JSON object.\n",
        "- For each field, include these keys:\n",
        "  - \"{field_id}_value\"\n",
        "  - \"{field_id}_evidence\"\n",
        "  - \"{field_id}_source_sentence\"\n",
        "- If a value is not found, set \"{field_id}_value\" to \"NOT_FOUND\",\n",
        "  set \"{field_id}_evidence\" to a brief reason, and \"{field_id}_source_sentence\" to \"N/A\".\n",
        "\n",
        "**10-K Filing Text**:\n",
        "{context}\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 8. LLM Extraction Class (Transformers version)\n",
        "\n",
        "class EDGARExtractor:\n",
        "    def __init__(self, model, tokenizer, generation_config):\n",
        "        self.model = model\n",
        "        self.tokenizer = tokenizer\n",
        "        self.generation_config = generation_config\n",
        "\n",
        "    def _build_prompt(self, prompt_text):\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "            {\"role\": \"user\", \"content\": prompt_text},\n",
        "        ]\n",
        "        return self.tokenizer.apply_chat_template(\n",
        "            messages,\n",
        "            tokenize=False,\n",
        "            add_generation_prompt=True\n",
        "        )\n",
        "\n",
        "    def _generate(self, prompt):\n",
        "        inputs = self.tokenizer([prompt], return_tensors=\"pt\").to(self.model.device)\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model.generate(\n",
        "                **inputs,\n",
        "                **self.generation_config\n",
        "            )\n",
        "        return self.tokenizer.decode(\n",
        "            outputs[0][inputs.input_ids.shape[1]:],\n",
        "            skip_special_tokens=True\n",
        "        ).strip()\n",
        "\n",
        "    def _parse_json(self, response_text, question_id=None, is_batch=False):\n",
        "        try:\n",
        "            if is_batch:\n",
        "                json_match = re.search(r'\\{.*\\}', response_text, re.DOTALL)\n",
        "            else:\n",
        "                json_match = re.search(r'\\{[^{}]*\\}', response_text, re.DOTALL)\n",
        "            json_str = json_match.group(0) if json_match else response_text\n",
        "            return json.loads(json_str)\n",
        "        except json.JSONDecodeError as e:\n",
        "            label = question_id or \"batch\"\n",
        "            print(f\"  [JSON ERROR] {label}: {e}\")\n",
        "            print(f\"  Raw response: {response_text[:200]}...\")\n",
        "            return None\n",
        "\n",
        "    def extract_single(self, full_text, question_config):\n",
        "        if not full_text or not full_text.strip():\n",
        "            return \"NOT_FOUND\", \"NO_CONTEXT\", \"NO_CONTEXT\"\n",
        "        prompt_text = USER_TEMPLATE.format(\n",
        "            question=question_config[\"prompt\"],\n",
        "            context=full_text\n",
        "        )\n",
        "        prompt = self._build_prompt(prompt_text)\n",
        "        response_text = self._generate(prompt)\n",
        "        data = self._parse_json(response_text, question_id=question_config[\"id\"], is_batch=False)\n",
        "        if data is None:\n",
        "            return \"JSON_PARSE_ERROR\", response_text[:500], \"JSON_PARSE_ERROR\"\n",
        "        value = data.get(\"value\", \"PARSE_ERROR\")\n",
        "        evidence = data.get(\"evidence\", \"PARSE_ERROR\")\n",
        "        source_sentence = data.get(\"source_sentence\", \"PARSE_ERROR\")\n",
        "        if value:\n",
        "            value = str(value).strip().rstrip('.')\n",
        "        return value, evidence, source_sentence\n",
        "\n",
        "    def extract_batch(self, full_text, question_bank):\n",
        "        if not full_text or not full_text.strip():\n",
        "            return None\n",
        "        questions = \"\\n\".join([f\"- {q['id']}: {q['prompt']}\" for q in question_bank])\n",
        "        prompt_text = BATCH_USER_TEMPLATE.format(\n",
        "            questions=questions,\n",
        "            field_id=\"{field_id}\",\n",
        "            context=full_text\n",
        "        )\n",
        "        prompt = self._build_prompt(prompt_text)\n",
        "        response_text = self._generate(prompt)\n",
        "        return self._parse_json(response_text, is_batch=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 9. Evidence Verification (\"Judge\" Logic)\n",
        "\n",
        "def get_fingerprint(text):\n",
        "    \"\"\"Removes all non-alphanumeric characters for fuzzy matching.\"\"\"\n",
        "    return re.sub(r'[\\W_]+', '', text).lower()\n",
        "\n",
        "def verify_evidence(full_text, evidence_quote, value):\n",
        "    \"\"\"\n",
        "    Checks if the evidence quote actually exists in the full text.\n",
        "    Returns: \n",
        "        - True if verified (evidence found in text)\n",
        "        - False if not found (potential hallucination)\n",
        "        - \"NOT_APPLICABLE\" if value was NOT_FOUND (evidence is reasoning, not a quote)\n",
        "    \"\"\"\n",
        "    # If value is NOT_FOUND, evidence is reasoning - don't try to verify it exists\n",
        "    if value and str(value).upper() == \"NOT_FOUND\":\n",
        "        return \"NOT_APPLICABLE\"\n",
        "    \n",
        "    if not evidence_quote or evidence_quote in [\"NO_CONTEXT\", \"PARSE_ERROR\", \"JSON_PARSE_ERROR\", \"N/A\"]:\n",
        "        return None  # Missing data\n",
        "    \n",
        "    if not full_text:\n",
        "        return False\n",
        "    \n",
        "    # 1. Exact match\n",
        "    if evidence_quote in full_text:\n",
        "        return True\n",
        "    \n",
        "    # 2. Normalized match (ignore whitespace/punctuation differences)\n",
        "    clean_text = \" \".join(full_text.split()).lower()\n",
        "    clean_evd = \" \".join(evidence_quote.split()).lower()\n",
        "    \n",
        "    if clean_evd in clean_text:\n",
        "        return True\n",
        "    \n",
        "    # 3. Fingerprint match (ignore all punctuation)\n",
        "    fp_text = get_fingerprint(full_text)\n",
        "    fp_evd = get_fingerprint(evidence_quote)\n",
        "    \n",
        "    if len(fp_evd) > 10 and fp_evd in fp_text:\n",
        "        return True\n",
        "    \n",
        "    return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 10. Load Dataset (from existing notebook pattern)\n",
        "\n",
        "def load_edgar_dataset():\n",
        "    \"\"\"Load the EDGAR corpus with streaming.\"\"\"\n",
        "    return load_dataset(\n",
        "        \"c3po-ai/edgar-corpus\",\n",
        "        \"default\",\n",
        "        split=\"train\",\n",
        "        streaming=True,\n",
        "        revision=\"refs/convert/parquet\",\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 11. Process Single Document\n",
        "\n",
        "def process_document(doc, extractor):\n",
        "    \"\"\"\n",
        "    Extracts all fields from a single document.\n",
        "    Returns a dict with all columns for the output CSV.\n",
        "    \"\"\"\n",
        "    result = {\n",
        "        \"filename\": doc.get(\"filename\"),\n",
        "        \"cik\": doc.get(\"cik\"),\n",
        "        \"year\": doc.get(\"year\"),\n",
        "    }\n",
        "    for key in SECTION_KEYS:\n",
        "        result[key] = doc.get(key, \"\")\n",
        "    \n",
        "    # Build full context once\n",
        "    full_text = build_full_context(doc)\n",
        "    result[\"full_text\"] = full_text  # Store for manual review\n",
        "    \n",
        "    def is_found(value):\n",
        "        return str(value) not in [\n",
        "            \"NOT_FOUND\", \"NO_CONTENT\", \"NO_CONTEXT\", \"JSON_PARSE_ERROR\", \"PARSE_ERROR\", \"ERROR\", \"None\"\n",
        "        ]\n",
        "    \n",
        "    if not full_text:\n",
        "        # No content - mark all fields as not found\n",
        "        for q in QUESTION_BANK:\n",
        "            field_id = q[\"id\"]\n",
        "            result[f\"{field_id}_value\"] = \"NO_CONTENT\"\n",
        "            result[f\"{field_id}_evidence\"] = \"NO_CONTENT\"\n",
        "            result[f\"{field_id}_source_sentence\"] = \"NO_CONTENT\"\n",
        "            result[f\"{field_id}_evidence_verified\"] = None\n",
        "            result[f\"{field_id}_found\"] = False\n",
        "        return result\n",
        "    \n",
        "    if USE_BATCH_MODE:\n",
        "        batch_data = extractor.extract_batch(full_text, QUESTION_BANK)\n",
        "        if not batch_data:\n",
        "            for q in QUESTION_BANK:\n",
        "                field_id = q[\"id\"]\n",
        "                result[f\"{field_id}_value\"] = \"ERROR\"\n",
        "                result[f\"{field_id}_evidence\"] = \"ERROR\"\n",
        "                result[f\"{field_id}_source_sentence\"] = \"ERROR\"\n",
        "                result[f\"{field_id}_evidence_verified\"] = None\n",
        "                result[f\"{field_id}_found\"] = False\n",
        "            return result\n",
        "        for q in QUESTION_BANK:\n",
        "            field_id = q[\"id\"]\n",
        "            value = batch_data.get(f\"{field_id}_value\", \"NOT_FOUND\")\n",
        "            evidence = batch_data.get(f\"{field_id}_evidence\", \"NOT_FOUND\")\n",
        "            source_sentence = batch_data.get(f\"{field_id}_source_sentence\", \"NOT_FOUND\")\n",
        "            evidence_verified = verify_evidence(full_text, evidence, value)\n",
        "            result[f\"{field_id}_value\"] = value\n",
        "            result[f\"{field_id}_evidence\"] = evidence\n",
        "            result[f\"{field_id}_source_sentence\"] = source_sentence\n",
        "            result[f\"{field_id}_evidence_verified\"] = evidence_verified\n",
        "            result[f\"{field_id}_found\"] = is_found(value)\n",
        "        return result\n",
        "    \n",
        "    # Extract each field (single mode)\n",
        "    for question in QUESTION_BANK:\n",
        "        field_id = question[\"id\"]\n",
        "        print(f\"Extracting {field_id} from {result['filename']}...\")\n",
        "        value, evidence, source_sentence = extractor.extract_single(full_text, question)\n",
        "        # Verify evidence exists in text \n",
        "        print(f\"  Verifying evidence for {field_id} from {result['filename']}...\")\n",
        "        evidence_verified = verify_evidence(full_text, evidence, value)\n",
        "        result[f\"{field_id}_value\"] = value\n",
        "        result[f\"{field_id}_evidence\"] = evidence\n",
        "        result[f\"{field_id}_source_sentence\"] = source_sentence\n",
        "        result[f\"{field_id}_evidence_verified\"] = evidence_verified\n",
        "        result[f\"{field_id}_found\"] = is_found(value)\n",
        "    \n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 12. Main Extraction Loop\n",
        "\n",
        "def run_extraction(\n",
        "    output_file=OUTPUT_FILE,\n",
        "    limit=MAX_DOCUMENTS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "):\n",
        "    \"\"\"\n",
        "    Main extraction loop with resume support and batch checkpointing.\n",
        "    \"\"\"\n",
        "    print(f\"--- COMBINED EXTRACTION: {limit} documents ---\")\n",
        "    extractor = EDGARExtractor(model, tokenizer, GENERATION_CONFIG)\n",
        "    \n",
        "    # 1. Resume support: Load existing progress\n",
        "    if os.path.exists(output_file):\n",
        "        df_results = pd.read_csv(output_file)\n",
        "        df_results = fill_missing_text_columns(df_results)\n",
        "        processed_files = set(df_results[\"filename\"].tolist())\n",
        "        print(f\"Resuming: {len(processed_files)} documents already processed.\")\n",
        "    else:\n",
        "        df_results = pd.DataFrame()\n",
        "        processed_files = set()\n",
        "    \n",
        "    # 2. Load dataset\n",
        "    dataset = load_edgar_dataset()\n",
        "    \n",
        "    current_batch = []\n",
        "    total_processed = len(processed_files)\n",
        "    new_processed = 0\n",
        "    \n",
        "    # 3. Main loop\n",
        "    for doc in tqdm(dataset, desc=\"Extracting\", total=limit):\n",
        "        fname = doc.get(\"filename\")\n",
        "        \n",
        "        # Skip if already processed\n",
        "        if fname in processed_files:\n",
        "            continue\n",
        "        \n",
        "        # Limit check\n",
        "        if total_processed + new_processed >= limit:\n",
        "            break\n",
        "        \n",
        "        # Process document\n",
        "        result = process_document(doc, extractor)\n",
        "        current_batch.append(result)\n",
        "        new_processed += 1\n",
        "        \n",
        "        # Batch checkpoint\n",
        "        if len(current_batch) >= batch_size:\n",
        "            df_batch = pd.DataFrame(current_batch)\n",
        "            df_batch = fill_missing_text_columns(df_batch)\n",
        "            df_results = pd.concat([df_results, df_batch], ignore_index=True)\n",
        "            df_results.to_csv(output_file, index=False)\n",
        "            current_batch = []\n",
        "            \n",
        "            # Memory cleanup\n",
        "            gc.collect()\n",
        "            torch.cuda.empty_cache()\n",
        "            print(f\"  [Checkpoint] Saved {total_processed + new_processed}/{limit} docs.\")\n",
        "    \n",
        "    # 4. Final save\n",
        "    if current_batch:\n",
        "        df_batch = pd.DataFrame(current_batch)\n",
        "        df_batch = fill_missing_text_columns(df_batch)\n",
        "        df_results = pd.concat([df_results, df_batch], ignore_index=True)\n",
        "        df_results.to_csv(output_file, index=False)\n",
        "    \n",
        "    print(f\"--- EXTRACTION COMPLETE: {output_file} ---\")\n",
        "    return df_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 13. Run Extraction\n",
        "\n",
        "df_extracted = run_extraction(\n",
        "    output_file=OUTPUT_FILE,\n",
        "    limit=MAX_DOCUMENTS,\n",
        "    batch_size=BATCH_SIZE,\n",
        ")\n",
        "\n",
        "# Display sample results\n",
        "print(f\"\\nTotal rows: {len(df_extracted)}\")\n",
        "display(df_extracted.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 14. Quality Report\n",
        "\n",
        "def generate_quality_report(df):\n",
        "    \"\"\"Generate a summary of extraction quality.\"\"\"\n",
        "    print(\"\\n=== EXTRACTION QUALITY REPORT ===\")\n",
        "    print(f\"Total documents: {len(df)}\")\n",
        "    print()\n",
        "    \n",
        "    for q in QUESTION_BANK:\n",
        "        field_id = q[\"id\"]\n",
        "        value_col = f\"{field_id}_value\"\n",
        "        verified_col = f\"{field_id}_evidence_verified\"\n",
        "        \n",
        "        if value_col not in df.columns:\n",
        "            continue\n",
        "        \n",
        "        total = len(df)\n",
        "        found = len(df[~df[value_col].isin([\"NOT_FOUND\", \"NO_CONTENT\", \"JSON_PARSE_ERROR\"])])\n",
        "        if verified_col in df.columns:\n",
        "            verified = df[verified_col].sum() if df[verified_col].dtype == bool else 0\n",
        "        else:\n",
        "            verified = \"N/A\"\n",
        "        \n",
        "        print(f\"{field_id}:\")\n",
        "        print(f\"  Found: {found}/{total} ({100*found/total:.1f}%)\")\n",
        "        print(f\"  Evidence Verified: {verified}\")\n",
        "        print()\n",
        "\n",
        "if not df_extracted.empty:\n",
        "    generate_quality_report(df_extracted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 15. Inspect Specific Results (by row number)\n",
        "\n",
        "ROW_NUMBER = 0  # Change this to inspect different rows\n",
        "\n",
        "if not df_extracted.empty and ROW_NUMBER < len(df_extracted):\n",
        "    row = df_extracted.iloc[ROW_NUMBER]\n",
        "    \n",
        "    print(f\"=== ROW {ROW_NUMBER}: {row['filename']} ===\")\n",
        "    print(f\"CIK: {row['cik']} | Year: {row['year']}\")\n",
        "    print()\n",
        "    \n",
        "    for q in QUESTION_BANK:\n",
        "        field_id = q[\"id\"]\n",
        "        print(f\"--- {field_id} ---\")\n",
        "        print(f\"  Value: {row[f'{field_id}_value']}\")\n",
        "        print(f\"  Evidence: {row[f'{field_id}_evidence']}\")\n",
        "        print(f\"  Verified: {row[f'{field_id}_evidence_verified']}\")\n",
        "        print()\n",
        "else:\n",
        "    print(f\"Row {ROW_NUMBER} not found. DataFrame has {len(df_extracted)} rows.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "ROW_TO_INSPECT = 0  # Change this to view different rows\n",
        "if not df_extracted.empty and ROW_TO_INSPECT < len(df_extracted):\n",
        "    row = df_extracted.iloc[ROW_TO_INSPECT]\n",
        "    \n",
        "    print(f\"=== FULL TEXT: {row['filename']} ===\")\n",
        "    print(f\"Length: {len(row['full_text'])} characters\")\n",
        "    print(\"=\" * 60)\n",
        "    print(row['full_text'])\n",
        "else:\n",
        "    print(f\"Row {ROW_TO_INSPECT} not found.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def split_combined_df_by_feature(\n",
        "    df,\n",
        "    output_dir=\"./split_features/\",\n",
        "    id_columns=None,\n",
        "):\n",
        "    \"\"\"\n",
        "    Split a combined extraction DataFrame into separate CSVs per feature.\n",
        "    \n",
        "    Args:\n",
        "        df: The master DataFrame containing all features.\n",
        "        output_dir: Directory to save the split CSV files.\n",
        "        id_columns: List of identity columns to keep in each file.\n",
        "                    Default: [\"filename\", \"cik\", \"year\"]\n",
        "    \n",
        "    Returns:\n",
        "        Dict mapping feature_id -> output file path.\n",
        "    \n",
        "    Example Output Files:\n",
        "        - split_features/extracted_registrant_name.csv\n",
        "        - split_features/extracted_employee_count.csv\n",
        "        - ...\n",
        "    \"\"\"\n",
        "    if id_columns is None:\n",
        "        id_columns = [\"filename\", \"cik\", \"year\"]\n",
        "    \n",
        "    # Create output directory if needed\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    \n",
        "    # Discover which features are in the DataFrame\n",
        "    # Pattern: {feature_id}_value, {feature_id}_evidence, etc.\n",
        "    feature_ids = set()\n",
        "    for col in df.columns:\n",
        "        if col.endswith(\"_value\"):\n",
        "            feature_id = col.replace(\"_value\", \"\")\n",
        "            feature_ids.add(feature_id)\n",
        "    \n",
        "    if not feature_ids:\n",
        "        print(\"No feature columns found in DataFrame. Looking for *_value columns.\")\n",
        "        return {}\n",
        "    \n",
        "    print(f\"Found {len(feature_ids)} features to split: {sorted(feature_ids)}\")\n",
        "    \n",
        "    output_files = {}\n",
        "    \n",
        "    for feature_id in sorted(feature_ids):\n",
        "        # Define column patterns for this feature\n",
        "        feature_cols = [\n",
        "            f\"{feature_id}_value\",\n",
        "            f\"{feature_id}_evidence\",\n",
        "            f\"{feature_id}_source_sentence\",\n",
        "            f\"{feature_id}_evidence_verified\",\n",
        "        ]\n",
        "        \n",
        "        # Filter to columns that actually exist\n",
        "        existing_feature_cols = [c for c in feature_cols if c in df.columns]\n",
        "        \n",
        "        if not existing_feature_cols:\n",
        "            print(f\"  [SKIP] {feature_id}: No columns found.\")\n",
        "            continue\n",
        "        \n",
        "        # Select identity + feature columns\n",
        "        cols_to_keep = [c for c in id_columns if c in df.columns] + existing_feature_cols\n",
        "        \n",
        "        df_feature = df[cols_to_keep].copy()\n",
        "        \n",
        "        # Output path\n",
        "        output_path = os.path.join(output_dir, f\"extracted_{feature_id}.csv\")\n",
        "        \n",
        "        df_feature.to_csv(output_path, index=False)\n",
        "        output_files[feature_id] = output_path\n",
        "        \n",
        "        # Summary\n",
        "        value_col = f\"{feature_id}_value\"\n",
        "        total_rows = len(df_feature)\n",
        "        found_count = len(df_feature[~df_feature[value_col].isin([\"NOT_FOUND\", \"NO_CONTENT\", \"JSON_PARSE_ERROR\", None])])\n",
        "        \n",
        "        print(f\"  âœ“ {feature_id}: {output_path}\")\n",
        "        print(f\"      Rows: {total_rows} | Found: {found_count} ({100*found_count/total_rows:.1f}%)\")\n",
        "    \n",
        "    print(f\"\\n--- SPLIT COMPLETE: {len(output_files)} files written to {output_dir} ---\")\n",
        "    return output_files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Split Combined DataFrame ---\n",
        "# After running full extraction, split into separate files:\n",
        "#\n",
        "if not df_extracted.empty:\n",
        "    output_paths = split_combined_df_by_feature(\n",
        "        df=df_extracted,\n",
        "        output_dir=\"./split_features/\",\n",
        "    )\n",
        "    print(output_paths)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# EDGAR Ground Truth Singular Extraction (Full Context)\n",
        "\n",
        "**Goal**: Extract 1 field from SEC 10-K filings with evidence provenance (using all sections this time).\n",
        "\n",
        "**Model**: Llama 3.3 70B Instruct via **Transformers** (HuggingFace)\n",
        "\n",
        "**Strategy**: Per-field sequential extraction with JSON structured output.\n",
        "\n",
        "**Output**: CSV with `{field}_value`, `{field}_evidence`, `{field}_source_sentence`, `{field}_evidence_verified` the field."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# **Purpose**: Extract a single feature from QUESTION_BANK to a CSV, with \n",
        "# append/merge support like `discover_new_feature` in the single notebook.\n",
        "#\n",
        "# Uses the existing Transformers setup (model, tokenizer, GENERATION_CONFIG) from this notebook.\n",
        "# ==============================================================================\n",
        "\n",
        "def merge_and_save_to_csv(df_master, batch_data, output_path):\n",
        "    \"\"\"\n",
        "    Merge new feature columns into existing master DataFrame.\n",
        "    - If filename exists: Add/update the feature columns for that row.\n",
        "    - If filename is new: Append the entire row.\n",
        "    \n",
        "    Adapted from extract_edgar_gt_single.ipynb's merge_and_save.\n",
        "    \"\"\"\n",
        "    df_batch = pd.DataFrame(batch_data)\n",
        "    \n",
        "    if df_master.empty:\n",
        "        df_master = df_batch\n",
        "    else:\n",
        "        # Normalize merge key to string\n",
        "        df_master[\"filename\"] = df_master[\"filename\"].astype(str)\n",
        "        df_batch[\"filename\"] = df_batch[\"filename\"].astype(str)\n",
        "        \n",
        "        # Drop identity columns from batch to prevent duplicates\n",
        "        batch_feature_cols = [col for col in df_batch.columns if col not in [\"filename\", \"cik\", \"year\"]]\n",
        "        df_batch_slim = df_batch[[\"filename\"] + batch_feature_cols]\n",
        "        \n",
        "        # Merge on filename (outer join to add new filenames)\n",
        "        df_master = pd.merge(\n",
        "            df_master,\n",
        "            df_batch_slim,\n",
        "            on=\"filename\",\n",
        "            how=\"outer\",\n",
        "            suffixes=(\"\", \"_new\")\n",
        "        )\n",
        "        \n",
        "        # Fill in cik/year for new rows\n",
        "        # Fixed: Use vectorized mapping to avoid .loc assignment type errors and loops\n",
        "        if \"cik\" in df_master.columns and df_master[\"cik\"].isna().any():\n",
        "            cik_map = df_batch.set_index(\"filename\")[\"cik\"]\n",
        "            df_master[\"cik\"] = df_master[\"cik\"].fillna(df_master[\"filename\"].map(cik_map))\n",
        "            \n",
        "        if \"year\" in df_master.columns and df_master[\"year\"].isna().any():\n",
        "            year_map = df_batch.set_index(\"filename\")[\"year\"]\n",
        "            df_master[\"year\"] = df_master[\"year\"].fillna(df_master[\"filename\"].map(year_map))\n",
        "        \n",
        "        # Cleanup duplicate columns (e.g., 'value_new' -> merge into 'value')\n",
        "        for col in list(df_master.columns):\n",
        "            if col.endswith(\"_new\"):\n",
        "                base_col = col.replace(\"_new\", \"\")\n",
        "                if base_col in df_master.columns:\n",
        "                    df_master[base_col] = df_master[base_col].fillna(df_master[col])\n",
        "                else:\n",
        "                    df_master.rename(columns={col: base_col}, inplace=True)\n",
        "                if col in df_master.columns:\n",
        "                    df_master.drop(columns=[col], inplace=True)\n",
        "    \n",
        "    df_master.to_csv(output_path, index=False)\n",
        "    return df_master\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def run_single_feature_extraction(\n",
        "    feature_id,\n",
        "    output_file=\"single_feature_extracted.csv\",\n",
        "    limit=MAX_DOCUMENTS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "):\n",
        "    \"\"\"\n",
        "    Extract a SINGLE feature from QUESTION_BANK using Transformers.\n",
        "    \n",
        "    Supports:\n",
        "    - **Resume**: Skips documents already processed for this feature.\n",
        "    - **Merge**: If file exists with other features, adds new columns.\n",
        "    - **Append**: If file exists but new documents are processed, appends rows.\n",
        "    \n",
        "    Args:\n",
        "        feature_id: The 'id' of the question in QUESTION_BANK to extract.\n",
        "        output_file: Path to the output CSV (will be created or merged into).\n",
        "        limit: Maximum number of documents to process.\n",
        "        batch_size: Checkpoint interval (saves every N docs).\n",
        "    \n",
        "    Returns:\n",
        "        DataFrame with extraction results.\n",
        "    \"\"\"\n",
        "    print(f\"--- SINGLE FEATURE EXTRACTION: {feature_id} ---\")\n",
        "    extractor = EDGARExtractor(model, tokenizer, GENERATION_CONFIG)\n",
        "    \n",
        "    # 1. Validate feature_id exists in QUESTION_BANK\n",
        "    question_config = None\n",
        "    for q in QUESTION_BANK:\n",
        "        if q[\"id\"] == feature_id:\n",
        "            question_config = q\n",
        "            break\n",
        "    \n",
        "    if question_config is None:\n",
        "        raise ValueError(f\"Feature '{feature_id}' not found in QUESTION_BANK. Available: {[q['id'] for q in QUESTION_BANK]}\")\n",
        "    \n",
        "    print(f\"  Question: {question_config['prompt'][:80]}...\")\n",
        "    \n",
        "    # 2. Column names for this feature\n",
        "    value_col = f\"{feature_id}_value\"\n",
        "    evidence_col = f\"{feature_id}_evidence\"\n",
        "    source_col = f\"{feature_id}_source_sentence\"\n",
        "    verified_col = f\"{feature_id}_evidence_verified\"\n",
        "    \n",
        "    # 3. Load existing progress (resume support)\n",
        "    if os.path.exists(output_file):\n",
        "        df_master = pd.read_csv(output_file)\n",
        "        # Check if this feature has already been processed for some docs\n",
        "        if value_col in df_master.columns:\n",
        "            processed_files = set(\n",
        "                df_master[df_master[value_col].notna()][\"filename\"].tolist()\n",
        "            )\n",
        "            print(f\"  Resuming: {len(processed_files)} documents already have '{feature_id}'.\")\n",
        "        else:\n",
        "            processed_files = set()\n",
        "            print(f\"  File exists, but '{feature_id}' is a NEW feature. Will merge columns.\")\n",
        "    else:\n",
        "        df_master = pd.DataFrame()\n",
        "        processed_files = set()\n",
        "        print(f\"  Starting fresh extraction.\")\n",
        "    \n",
        "    # 4. Load dataset\n",
        "    dataset = load_edgar_dataset()\n",
        "    \n",
        "    current_batch = []\n",
        "    total_processed = len(processed_files)\n",
        "    new_processed = 0\n",
        "    \n",
        "    # 5. Main extraction loop\n",
        "    for doc in tqdm(dataset, desc=f\"Extracting {feature_id}\", total=limit):\n",
        "        fname = doc.get(\"filename\")\n",
        "        \n",
        "        # Skip if already processed\n",
        "        if fname in processed_files:\n",
        "            continue\n",
        "        \n",
        "        # Limit check\n",
        "        if total_processed + new_processed >= limit:\n",
        "            break\n",
        "        \n",
        "        # Build full context\n",
        "        full_text = build_full_context(doc)\n",
        "        \n",
        "        # Extract this single field\n",
        "        value, evidence, source_sentence = extractor.extract_single(\n",
        "            full_text, question_config\n",
        "        )\n",
        "        \n",
        "        # Verify evidence\n",
        "        evidence_verified = verify_evidence(full_text, evidence, value)\n",
        "        \n",
        "        # Build result row\n",
        "        row = {\n",
        "            \"filename\": fname,\n",
        "            \"cik\": doc.get(\"cik\"),\n",
        "            \"year\": doc.get(\"year\"),\n",
        "            value_col: value,\n",
        "            evidence_col: evidence,\n",
        "            source_col: source_sentence,\n",
        "            verified_col: evidence_verified,\n",
        "        }\n",
        "        \n",
        "        current_batch.append(row)\n",
        "        new_processed += 1\n",
        "        \n",
        "        # Batch checkpoint\n",
        "        if len(current_batch) >= batch_size:\n",
        "            df_master = merge_and_save_to_csv(df_master, current_batch, output_file)\n",
        "            current_batch = []\n",
        "            \n",
        "            gc.collect()\n",
        "            torch.cuda.empty_cache()\n",
        "            print(f\"  [Checkpoint] Saved {total_processed + new_processed}/{limit} docs.\")\n",
        "    \n",
        "    # 6. Final save\n",
        "    if current_batch:\n",
        "        df_master = merge_and_save_to_csv(df_master, current_batch, output_file)\n",
        "    \n",
        "    print(f\"--- SINGLE FEATURE EXTRACTION COMPLETE: {output_file} ---\")\n",
        "    print(f\"  Total documents with '{feature_id}': {len(df_master[df_master[value_col].notna()]) if value_col in df_master.columns else 0}\")\n",
        "    \n",
        "    return df_master"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Single Feature Extraction ---\n",
        "# Extract ONLY 'employee_count' to a file (with merge/append support):\n",
        "#\n",
        "df_single = run_single_feature_extraction(\n",
        "    feature_id=\"employees_count_total\",\n",
        "    output_file=\"employee_count_only.csv\",\n",
        "    limit=100,\n",
        "    batch_size=10,\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
