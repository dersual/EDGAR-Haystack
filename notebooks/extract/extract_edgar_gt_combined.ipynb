{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# EDGAR Ground Truth Combined Extraction (Full Context)\n",
        "\n",
        "**Goal**: Extract all 8 fields from SEC 10-K filings with evidence provenance.\n",
        "\n",
        "**Model**: Llama 3.3 70B Instruct via vLLM on Lambda GPU\n",
        "\n",
        "**Strategy**: Per-field sequential extraction with JSON structured output.\n",
        "\n",
        "**Output**: CSV with `{field}_value`, `{field}_evidence`, `{field}_source_sentence`, `{field}_evidence_verified` for each field."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Installation (Run once on Lambda) \n",
        "#!export HF_TOKEN=\"your_token\"\n",
        "#!pip install -q vllm datasets pandas tqdm thefuzz python-Levenshtein"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2. Imports & Setup\n",
        "import os\n",
        "import re\n",
        "import gc\n",
        "import json\n",
        "import pandas as pd\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from datasets import load_dataset\n",
        "from vllm import LLM, SamplingParams\n",
        "\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "print(\"Setup Complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3. Load Model (Llama 3.3 70B Instruct via vLLM)\n",
        "\n",
        "MODEL_NAME = \"meta-llama/Llama-3.3-70B-Instruct\"\n",
        "\n",
        "print(f\"Loading {MODEL_NAME} via vLLM...\")\n",
        "llm = LLM(\n",
        "    model=MODEL_NAME,\n",
        "    tensor_parallel_size=torch.cuda.device_count(),  # Use all available GPUs\n",
        "    max_model_len=65536,  # 64K context to fit ~50-60K docs with room for output\n",
        "    enable_prefix_caching=True,  # Reduces attention dilution\n",
        "    gpu_memory_utilization=0.90,\n",
        "    dtype=\"bfloat16\",\n",
        ")\n",
        "print(f\"Model loaded on {torch.cuda.device_count()} GPU(s).\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4. Configuration\n",
        "\n",
        "OUTPUT_FILE = \"edgar_gt_combined_extracted.csv\"\n",
        "BATCH_SIZE = 10  # Save checkpoint every N documents\n",
        "MAX_DOCUMENTS = 250  # Total documents to process\n",
        "\n",
        "# Sampling parameters for deterministic output\n",
        "SAMPLING_PARAMS = SamplingParams(\n",
        "    temperature=0.0,\n",
        "    max_tokens=500,\n",
        "    stop=[\"}\"],  # Stop after JSON closes\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5. Question Bank (All 8 Fields)\n",
        "\n",
        "QUESTION_BANK = [\n",
        "    {\n",
        "        \"id\": \"registrant_name\",\n",
        "        \"prompt\": (\n",
        "            \"What is the exact legal name of the registrant? \"\n",
        "            \"1. Look for the very first sentence of the 'Business' section or the cover page intro \"\n",
        "            \"(e.g., 'Apple Inc. (the Registrant)...'). \"\n",
        "            \"2. Do NOT use 'Doing Business As' (DBA) names or brand names. \"\n",
        "            \"3. Do NOT include the stock ticker symbol. \"\n",
        "            \"4. Include legal suffixes like 'Inc.', 'Corp.', 'Ltd.' if present. \"\n",
        "            \"Answer with ONLY the legal name string.\"\n",
        "        ),\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"headquarters_city\",\n",
        "        \"prompt\": (\n",
        "            \"In which city are the registrant's *principal executive offices* physically located? \"\n",
        "            \"1. Look for the address under 'Executive Offices' or 'Address of Principal Executive Offices'. \"\n",
        "            \"2. CRITICAL WARNING: Do NOT return the city of the 'Registered Agent' or 'State of Incorporation' \"\n",
        "            \"(e.g., ignore 'Wilmington' or 'Dover' unless the CEO actually works there). \"\n",
        "            \"3. Ignore P.O. Boxes. \"\n",
        "            \"Answer with ONLY the city name.\"\n",
        "        ),\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"headquarters_state\",\n",
        "        \"prompt\": (\n",
        "            \"In which U.S. state are the registrant's *principal executive offices* physically located? \"\n",
        "            \"1. This is the state where the HQ building is, NOT necessarily the state of incorporation. \"\n",
        "            \"2. CRITICAL: If the text says 'Incorporated in Delaware' but 'Executive offices in California', \"\n",
        "            \"return CALIFORNIA. \"\n",
        "            \"Answer with ONLY the state name.\"\n",
        "        ),\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"original_incorporation_state\",\n",
        "        \"prompt\": (\n",
        "            \"In which U.S. state was the registrant *originally* incorporated or organized? \"\n",
        "            \"Follow this strict hierarchy: \"\n",
        "            \"1. PRIORITIZE HISTORY: Look for phrases like 'originally incorporated in', 'formerly organized in', \"\n",
        "            \"or 'predecessor company incorporated in'. \"\n",
        "            \"2. REINCORPORATION RULE: If the company reincorporated (e.g., moved from California to Delaware), \"\n",
        "            \"you MUST return the OLD state (California), not the current one. \"\n",
        "            \"3. MERGER EXCEPTION: Only if the registrant is a *new* successor entity formed by a merger, \"\n",
        "            \"return the state of that successor. \"\n",
        "            \"4. If no history is mentioned, return the current state. \"\n",
        "            \"Answer with ONLY the state name.\"\n",
        "        ),\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"original_incorporation_year\",\n",
        "        \"prompt\": (\n",
        "            \"In which year was the registrant *originally* incorporated or organized? \"\n",
        "            \"1. IGNORE 'FOUNDED' dates. Only look for 'incorporated', 'organized', or 'formed'. \"\n",
        "            \"2. REINCORPORATION RULE: If the text says 'originally incorporated in 1980' and 'reincorporated in 1995', \"\n",
        "            \"return the EARLIEST year (1980). \"\n",
        "            \"3. MERGER EXCEPTION: If the current entity was formed by a merger of equals, use the year of that merger. \"\n",
        "            \"Answer with ONLY the year (YYYY).\"\n",
        "        ),\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"employee_count\",\n",
        "        \"prompt\": (\n",
        "            \"What is the total number of employees the registrant has? \"\n",
        "            \"1. PREFER FULL-TIME: If the text distinguishes between full-time and part-time, return the full-time count. \"\n",
        "            \"2. If only 'total' is given, use that. \"\n",
        "            \"3. EXCLUDE: Do not count independent contractors, agents, or temporary staff unless they are the only number given. \"\n",
        "            \"4. FORMAT: Remove commas and return ONLY the integer (e.g., return 14500, not 14,500). \"\n",
        "            \"If the number is 'approximately 5,000', return 5000.\"\n",
        "        ),\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"ceo_lastname\",\n",
        "        \"prompt\": (\n",
        "            \"What is the LAST NAME of the registrant's current Chief Executive Officer (CEO)? \"\n",
        "            \"1. Look for 'Chief Executive Officer', 'CEO', or 'Principal Executive Officer'. \"\n",
        "            \"2. If 'Co-CEOs' are listed, pick the first one mentioned. \"\n",
        "            \"3. EXCLUDE titles (Mr., Dr.) and first/middle names. \"\n",
        "            \"4. If the CEO has a compound last name (e.g., 'Von Trap'), include the full last name. \"\n",
        "            \"Answer with ONLY the last name string.\"\n",
        "        ),\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"holder_record_amount\",\n",
        "        \"prompt\": (\n",
        "            \"What is the number of **holders of record** of the registrant's common stock? \"\n",
        "            \"1. KEYWORDS: Look for 'holders of record', 'shareholders of record', or 'record holders' in Item 5. \"\n",
        "            \"2. WHOLLY-OWNED RULE: If the text states the stock is 'wholly-owned', 'held solely by', or 'all outstanding stock is held by' a parent company, return **1**. \"\n",
        "            \"3. EXCLUDE BENEFICIAL OWNERS: Do not use counts of 'beneficial owners' or shares held in 'street name' unless strictly no other number exists. \"\n",
        "            \"4. MULTIPLE CLASSES: If Class A and Class B Common Stock are listed, SUM the record holders. Ignore Preferred Stock. \"\n",
        "            \"5. DATE PRIORITY: If multiple dates are provided (e.g., 'as of year-end' vs 'as of March 31'), choose the **most recent** date. \"\n",
        "            \"Return ONLY the integer (e.g., 4530). Remove commas and words like 'approximately'.\"\n",
        "        ),\n",
        "    },\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 6. Full Context Builder (Concatenates ALL Sections)\n",
        "\n",
        "SECTION_KEYS = [\n",
        "    \"section_1\", \"section_1A\", \"section_1B\", \"section_2\", \"section_3\",\n",
        "    \"section_4\", \"section_5\", \"section_6\", \"section_7\", \"section_7A\",\n",
        "    \"section_8\", \"section_9\", \"section_9A\", \"section_9B\", \"section_10\",\n",
        "    \"section_11\", \"section_12\", \"section_13\", \"section_14\", \"section_15\"\n",
        "]\n",
        "\n",
        "def build_full_context(doc):\n",
        "    \"\"\"\n",
        "    Concatenates ALL available sections from the 10-K filing.\n",
        "    Returns the full text with section headers for context.\n",
        "    \"\"\"\n",
        "    parts = []\n",
        "    for key in SECTION_KEYS:\n",
        "        section_text = doc.get(key, \"\")\n",
        "        if section_text and section_text.strip():\n",
        "            parts.append(f\"\\n\\n--- [{key.upper()}] ---\\n\\n{section_text}\")\n",
        "    \n",
        "    return \"\".join(parts) if parts else \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 7. Extraction Prompt Template\n",
        "\n",
        "EXTRACTION_TEMPLATE = \"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
        "\n",
        "You are a precise SEC 10-K filing data extraction assistant. You MUST:\n",
        "1. Extract information ONLY from the provided text.\n",
        "2. If the information is not found, return \"NOT_FOUND\" as the value.\n",
        "3. Always provide the exact quote from the text as evidence.\n",
        "4. Respond ONLY with valid JSON, nothing else.\n",
        "\n",
        "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
        "\n",
        "Read this SEC 10-K filing and answer the question.\n",
        "\n",
        "**Question**: {question}\n",
        "\n",
        "**Instructions**:\n",
        "- Provide your answer as a JSON object with exactly these keys:\n",
        "  - \"value\": The extracted answer (or \"NOT_FOUND\" if not present)\n",
        "  - \"evidence\": The EXACT substring from the text that supports your answer (copy word-for-word)\n",
        "  - \"source_sentence\": The complete sentence containing the evidence\n",
        "\n",
        "**10-K Filing Text**:\n",
        "{context}\n",
        "\n",
        "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
        "\n",
        "{{\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 8. LLM Extraction Function\n",
        "\n",
        "def extract_field(full_text, question_config, llm, sampling_params):\n",
        "    \"\"\"\n",
        "    Extracts a single field from the full text using the LLM.\n",
        "    Returns: (value, evidence, source_sentence)\n",
        "    \"\"\"\n",
        "    if not full_text or not full_text.strip():\n",
        "        return \"NOT_FOUND\", \"NO_CONTEXT\", \"NO_CONTEXT\"\n",
        "    \n",
        "    prompt = EXTRACTION_TEMPLATE.format(\n",
        "        question=question_config[\"prompt\"],\n",
        "        context=full_text\n",
        "    )\n",
        "    \n",
        "    # Generate with vLLM\n",
        "    outputs = llm.generate([prompt], sampling_params)\n",
        "    response_text = outputs[0].outputs[0].text.strip()\n",
        "    \n",
        "    # Parse JSON response\n",
        "    try:\n",
        "        # The response starts after we injected '{\"', so prepend it back\n",
        "        json_str = '{\"' + response_text\n",
        "        if not json_str.endswith('}'):\n",
        "            json_str += '}'\n",
        "        \n",
        "        data = json.loads(json_str)\n",
        "        value = data.get(\"value\", \"PARSE_ERROR\")\n",
        "        evidence = data.get(\"evidence\", \"PARSE_ERROR\")\n",
        "        source_sentence = data.get(\"source_sentence\", \"PARSE_ERROR\")\n",
        "        \n",
        "        # Clean up value\n",
        "        if value:\n",
        "            value = str(value).strip().rstrip('.')\n",
        "        \n",
        "        return value, evidence, source_sentence\n",
        "        \n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"  [JSON ERROR] {question_config['id']}: {e}\")\n",
        "        print(f\"  Raw response: {response_text[:200]}...\")\n",
        "        return \"JSON_PARSE_ERROR\", response_text[:500], \"JSON_PARSE_ERROR\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 9. Evidence Verification (\"Judge\" Logic)\n",
        "\n",
        "def get_fingerprint(text):\n",
        "    \"\"\"Removes all non-alphanumeric characters for fuzzy matching.\"\"\"\n",
        "    return re.sub(r'[\\W_]+', '', text).lower()\n",
        "\n",
        "def verify_evidence(full_text, evidence_quote):\n",
        "    \"\"\"\n",
        "    Checks if the evidence quote actually exists in the full text.\n",
        "    Returns: True if verified, False if not found (potential hallucination)\n",
        "    \"\"\"\n",
        "    if not evidence_quote or evidence_quote in [\"NOT_FOUND\", \"NO_CONTEXT\", \"PARSE_ERROR\", \"JSON_PARSE_ERROR\"]:\n",
        "        return None  # Not applicable\n",
        "    \n",
        "    if not full_text:\n",
        "        return False\n",
        "    \n",
        "    # 1. Exact match\n",
        "    if evidence_quote in full_text:\n",
        "        return True\n",
        "    \n",
        "    # 2. Normalized match (ignore whitespace/punctuation differences)\n",
        "    clean_text = \" \".join(full_text.split()).lower()\n",
        "    clean_evd = \" \".join(evidence_quote.split()).lower()\n",
        "    \n",
        "    if clean_evd in clean_text:\n",
        "        return True\n",
        "    \n",
        "    # 3. Fingerprint match (ignore all punctuation)\n",
        "    fp_text = get_fingerprint(full_text)\n",
        "    fp_evd = get_fingerprint(evidence_quote)\n",
        "    \n",
        "    if len(fp_evd) > 10 and fp_evd in fp_text:\n",
        "        return True\n",
        "    \n",
        "    return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 10. Load Dataset (from existing notebook pattern)\n",
        "\n",
        "def load_edgar_dataset():\n",
        "    \"\"\"Load the EDGAR corpus with streaming.\"\"\"\n",
        "    return load_dataset(\n",
        "        \"c3po-ai/edgar-corpus\",\n",
        "        \"default\",\n",
        "        split=\"train\",\n",
        "        streaming=True,\n",
        "        revision=\"refs/convert/parquet\",\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 11. Process Single Document\n",
        "\n",
        "def process_document(doc, llm, sampling_params):\n",
        "    \"\"\"\n",
        "    Extracts all 8 fields from a single document.\n",
        "    Returns a dict with all columns for the output CSV.\n",
        "    \"\"\"\n",
        "    result = {\n",
        "        \"filename\": doc.get(\"filename\"),\n",
        "        \"cik\": doc.get(\"cik\"),\n",
        "        \"year\": doc.get(\"year\"),\n",
        "    }\n",
        "    \n",
        "    # Build full context once\n",
        "    full_text = build_full_context(doc)\n",
        "    result[\"full_text\"] = full_text  # Store for manual review\n",
        "    \n",
        "    if not full_text:\n",
        "        # No content - mark all fields as not found\n",
        "        for q in QUESTION_BANK:\n",
        "            field_id = q[\"id\"]\n",
        "            result[f\"{field_id}_value\"] = \"NO_CONTENT\"\n",
        "            result[f\"{field_id}_evidence\"] = \"NO_CONTENT\"\n",
        "            result[f\"{field_id}_source_sentence\"] = \"NO_CONTENT\"\n",
        "            result[f\"{field_id}_evidence_verified\"] = None\n",
        "        return result\n",
        "    \n",
        "    # Extract each field\n",
        "    for question in QUESTION_BANK:\n",
        "        field_id = question[\"id\"]\n",
        "        \n",
        "        value, evidence, source_sentence = extract_field(\n",
        "            full_text, question, llm, sampling_params\n",
        "        )\n",
        "        \n",
        "        # Verify evidence exists in text\n",
        "        evidence_verified = verify_evidence(full_text, evidence)\n",
        "        \n",
        "        result[f\"{field_id}_value\"] = value\n",
        "        result[f\"{field_id}_evidence\"] = evidence\n",
        "        result[f\"{field_id}_source_sentence\"] = source_sentence\n",
        "        result[f\"{field_id}_evidence_verified\"] = evidence_verified\n",
        "    \n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 12. Main Extraction Loop\n",
        "\n",
        "def run_extraction(\n",
        "    output_file=OUTPUT_FILE,\n",
        "    limit=MAX_DOCUMENTS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "):\n",
        "    \"\"\"\n",
        "    Main extraction loop with resume support and batch checkpointing.\n",
        "    \"\"\"\n",
        "    print(f\"--- COMBINED EXTRACTION: {limit} documents ---\")\n",
        "    \n",
        "    # 1. Resume support: Load existing progress\n",
        "    if os.path.exists(output_file):\n",
        "        df_results = pd.read_csv(output_file)\n",
        "        processed_files = set(df_results[\"filename\"].tolist())\n",
        "        print(f\"Resuming: {len(processed_files)} documents already processed.\")\n",
        "    else:\n",
        "        df_results = pd.DataFrame()\n",
        "        processed_files = set()\n",
        "    \n",
        "    # 2. Load dataset\n",
        "    dataset = load_edgar_dataset()\n",
        "    \n",
        "    current_batch = []\n",
        "    total_processed = len(processed_files)\n",
        "    new_processed = 0\n",
        "    \n",
        "    # 3. Main loop\n",
        "    for doc in tqdm(dataset, desc=\"Extracting\", total=limit):\n",
        "        fname = doc.get(\"filename\")\n",
        "        \n",
        "        # Skip if already processed\n",
        "        if fname in processed_files:\n",
        "            continue\n",
        "        \n",
        "        # Limit check\n",
        "        if total_processed + new_processed >= limit:\n",
        "            break\n",
        "        \n",
        "        # Process document\n",
        "        result = process_document(doc, llm, SAMPLING_PARAMS)\n",
        "        current_batch.append(result)\n",
        "        new_processed += 1\n",
        "        \n",
        "        # Batch checkpoint\n",
        "        if len(current_batch) >= batch_size:\n",
        "            df_batch = pd.DataFrame(current_batch)\n",
        "            df_results = pd.concat([df_results, df_batch], ignore_index=True)\n",
        "            df_results.to_csv(output_file, index=False)\n",
        "            current_batch = []\n",
        "            \n",
        "            # Memory cleanup\n",
        "            gc.collect()\n",
        "            torch.cuda.empty_cache()\n",
        "            print(f\"  [Checkpoint] Saved {total_processed + new_processed}/{limit} docs.\")\n",
        "    \n",
        "    # 4. Final save\n",
        "    if current_batch:\n",
        "        df_batch = pd.DataFrame(current_batch)\n",
        "        df_results = pd.concat([df_results, df_batch], ignore_index=True)\n",
        "        df_results.to_csv(output_file, index=False)\n",
        "    \n",
        "    print(f\"--- EXTRACTION COMPLETE: {output_file} ---\")\n",
        "    return df_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 13. Run Extraction\n",
        "\n",
        "df_extracted = run_extraction(\n",
        "    output_file=OUTPUT_FILE,\n",
        "    limit=MAX_DOCUMENTS,\n",
        "    batch_size=BATCH_SIZE,\n",
        ")\n",
        "\n",
        "# Display sample results\n",
        "print(f\"\\nTotal rows: {len(df_extracted)}\")\n",
        "display(df_extracted.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 14. Quality Report\n",
        "\n",
        "def generate_quality_report(df):\n",
        "    \"\"\"Generate a summary of extraction quality.\"\"\"\n",
        "    print(\"\\n=== EXTRACTION QUALITY REPORT ===\")\n",
        "    print(f\"Total documents: {len(df)}\")\n",
        "    print()\n",
        "    \n",
        "    for q in QUESTION_BANK:\n",
        "        field_id = q[\"id\"]\n",
        "        value_col = f\"{field_id}_value\"\n",
        "        verified_col = f\"{field_id}_evidence_verified\"\n",
        "        \n",
        "        if value_col not in df.columns:\n",
        "            continue\n",
        "        \n",
        "        total = len(df)\n",
        "        found = len(df[~df[value_col].isin([\"NOT_FOUND\", \"NO_CONTENT\", \"JSON_PARSE_ERROR\"])])\n",
        "        if verified_col in df.columns:\n",
        "            verified = df[verified_col].sum() if df[verified_col].dtype == bool else 0\n",
        "        else:\n",
        "            verified = \"N/A\"\n",
        "        \n",
        "        print(f\"{field_id}:\")\n",
        "        print(f\"  Found: {found}/{total} ({100*found/total:.1f}%)\")\n",
        "        print(f\"  Evidence Verified: {verified}\")\n",
        "        print()\n",
        "\n",
        "if not df_extracted.empty:\n",
        "    generate_quality_report(df_extracted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 15. Inspect Specific Results (by row number)\n",
        "\n",
        "ROW_NUMBER = 0  # Change this to inspect different rows\n",
        "\n",
        "if not df_extracted.empty and ROW_NUMBER < len(df_extracted):\n",
        "    row = df_extracted.iloc[ROW_NUMBER]\n",
        "    \n",
        "    print(f\"=== ROW {ROW_NUMBER}: {row['filename']} ===\")\n",
        "    print(f\"CIK: {row['cik']} | Year: {row['year']}\")\n",
        "    print()\n",
        "    \n",
        "    for q in QUESTION_BANK:\n",
        "        field_id = q[\"id\"]\n",
        "        print(f\"--- {field_id} ---\")\n",
        "        print(f\"  Value: {row[f'{field_id}_value']}\")\n",
        "        print(f\"  Evidence: {row[f'{field_id}_evidence']}\")\n",
        "        print(f\"  Verified: {row[f'{field_id}_evidence_verified']}\")\n",
        "        print()\n",
        "else:\n",
        "    print(f\"Row {ROW_NUMBER} not found. DataFrame has {len(df_extracted)} rows.\")# 15. Inspect Specific Results (Optional)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "ROW_TO_INSPECT = 0  # Change this to view different rows\n",
        "if not df_extracted.empty and ROW_TO_INSPECT < len(df_extracted):\n",
        "    row = df_extracted.iloc[ROW_TO_INSPECT]\n",
        "    \n",
        "    print(f\"=== FULL TEXT: {row['filename']} ===\")\n",
        "    print(f\"Length: {len(row['full_text'])} characters\")\n",
        "    print(\"=\" * 60)\n",
        "    print(row['full_text'])\n",
        "else:\n",
        "    print(f\"Row {ROW_TO_INSPECT} not found.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
